{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cf9dc83",
   "metadata": {},
   "source": [
    "# 2024-03-14\n",
    "## Python Study for PBI Lab Crew"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f736817d",
   "metadata": {},
   "source": [
    "# 킹갓엠페러제너럴충무공마제스티하이퍼울트라\n",
    "# SCIKIT-LEARN\n",
    "https://scikit-learn.org/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47587425",
   "metadata": {},
   "source": [
    "# 오늘 학습 목표 \n",
    "## 1. 왜 머신러닝인가\n",
    "## 2. 어떻게 학습되는 가\n",
    "## 3. 차원이란?\n",
    "## 4. KNN 해보기\n",
    "## 5. SVM 해보기 \n",
    "\n",
    "\n",
    "### 다음 주 모델 로스, opt, 이론 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2978a46d",
   "metadata": {},
   "source": [
    "## 아직까지도 많은 사람들이 뭐가 AI, ML(기계학습)과  DL(Deep Learning)을 혼동해요\n",
    "![img](https://upload.wikimedia.org/wikipedia/commons/6/68/AI_relation_to_Generative_Models_subset%2C_venn_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92571981",
   "metadata": {},
   "source": [
    "간단하게 생각하면<br>\n",
    "모델이 판단을 하는 가 -> AI <br>\n",
    "모델이 학습이 가능한 가 -> ML <br>\n",
    "신경망 구조를 가지는 가 -> DL (NN) <br>\n",
    "모델의 결과가 없던 것인가 -> GM <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b365dcc4",
   "metadata": {},
   "source": [
    "![img](수업자료1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b290bcf7",
   "metadata": {},
   "source": [
    "![img](수업자료2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c027ce",
   "metadata": {},
   "source": [
    "![img](수업자료3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d63410",
   "metadata": {},
   "source": [
    "# 그럼 왜? 우리는 모델이 학습한다 라고 하는 것인가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6522b32",
   "metadata": {},
   "source": [
    "## \"주어진\" 데이터로부터 \"스스로\" 파라미터(웨이트 등)을 수정해가며 더 나은 성능을 가지는 모델이 되어간다. \"새로운\" 데이터에서도 유의한 성능을 낼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c877e0",
   "metadata": {},
   "source": [
    "위 문장을 통해서 알 수 있는 것처럼 기계학습 모델은 주어진 데이터를 학습하여 새로운 데이터에서도 성능을 낼 수 있는 모델을 말합니다.<br>\n",
    " 학습을 하는 과정은 성능을 평가하는 과정, 스스로 파라미터를 Update 하는 과정으로 크게 나눌 수 있습니다. 두 과정을 반복하며 더 나은 모델이 되어가는 것이죠<br>\n",
    " 이렇게 학습하는 것을 fit/fitting 이라합니다.\n",
    " \n",
    "아무리 주어진 학습에 대하여 높은 성능을 가지더라도 새로운 데이터에 성능이 시원찮다면 옳바르게 학습된 모델이라 보기힘들다. 아래 그림을 보면 쉽게 이해할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c910ebd",
   "metadata": {},
   "source": [
    "![img](수업자료4.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310150ce",
   "metadata": {},
   "source": [
    "이처럼 모델을 적절하게 학습시키는 것이 중요한데 그것을 위한 학습방법이 아래와 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a117a4",
   "metadata": {},
   "source": [
    "![img](수업자료5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c0d69f",
   "metadata": {},
   "source": [
    "먼저 모델 학습에 사용될 데이터, 학습시 성능평가를 위한 데이터와 모델의 성능평가를 위한 데이터로 각각 나누어야 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c1fb05",
   "metadata": {},
   "source": [
    "![img](수업자료6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be41990",
   "metadata": {},
   "source": [
    "    학습시 성능평가를 위한 데이터를 모델이 학습하지 않는 것은 데이터가 충분하지 않을 때 데이터를 낭비하는 것이기 때문에 이를 보완하기위해 위 같은 CV 방법을 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cf2adb",
   "metadata": {},
   "source": [
    "# 차원??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d441a7",
   "metadata": {},
   "source": [
    "![img](수업자료7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cdcbcf",
   "metadata": {},
   "source": [
    "![img](수업자료8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924f90bb",
   "metadata": {},
   "source": [
    "![img](수업자료9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6adef10",
   "metadata": {},
   "source": [
    "![img](수업자료10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c79c47",
   "metadata": {},
   "source": [
    "![img](수업자료11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af076076",
   "metadata": {},
   "source": [
    "## cf> 새로운 공간으로 데이터를 변환하는 것을 임베딩(Embedding)이라 합니다. ex> 자연어 -> 벡터 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c738fab",
   "metadata": {},
   "source": [
    "우리는 차원 축소 방법 PCA와 UMAP을 각각 실습해볼 예정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19d846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import umap\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tmm = pd.read_csv(\"kyuchan.TMM.matrix\",sep = \"\\t\", index_col=0)\n",
    "tmm = tmm[['N10-na1', 'N10-na2', 'N10-na3', 'N10-na4', 'N10-na5', 'N11-na1',\n",
    "       'N11-na2', 'N11-na3', 'N11-na4', 'N11-na5', 'P10-dh1', 'P10-dh2',\n",
    "       'P10-dh3', 'P10-dh4', 'P10-dh5', 'P10-ur1', 'P10-ur2', 'P10-ur3',\n",
    "       'P10-ur4', 'P10-ur5', 'P11-an1', 'P11-an2', 'P11-an3', 'P11-an4',\n",
    "       'P11-an5', 'P11-as1', 'P11-as2', 'P11-as3', 'P11-as4', 'P11-as5']]\n",
    "samples = pd.DataFrame()\n",
    "samples[\"Sample\"] = [0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc3f53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = [10, 10]\n",
    "plt.rcParams[\"figure.dpi\"] = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4ca320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sample_PCA(TPM_df,Samples_df):\n",
    "    pca_data =TPM_df.T\n",
    "    pca = PCA(n_components=2)\n",
    "\n",
    "    pca.fit(pca_data)\n",
    "    x_pca = pca.transform(pca_data)\n",
    "\n",
    "    pca_df = pd.DataFrame(x_pca)\n",
    "    pca_df['Sample'] = Samples_df[\"Sample\"]\n",
    "    pca_df.head()\n",
    "\n",
    "    sns.scatterplot(data=pca_df, x=0, y=1, hue='Sample')\n",
    "    \n",
    "    plt.xlabel(\"PC 1 [{}%]\".format(round(pca.explained_variance_ratio_[0]*100,2)))\n",
    "    plt.ylabel(\"PC 2 [{}%]\".format(round(pca.explained_variance_ratio_[1]*100,2)))\n",
    "    plt.legend(loc = 2, bbox_to_anchor = (1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08ecb1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Sample_PCA(tmm, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f85d11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sample_UMAP(TPM_df,Samples_df):\n",
    "    reducer = umap.UMAP()\n",
    "\n",
    "    # Fit the UMAP object to the data and transform the data to 2D\n",
    "    embedding = reducer.fit_transform(TPM_df.T)\n",
    "    umap_df = pd.DataFrame(embedding)\n",
    "    umap_df['Fireblight'] = samples[\"Sample\"]\n",
    "    umap_df.head()\n",
    "    # Visualize the results using matplotlib\n",
    "    sns.scatterplot(data=umap_df, x=0, y=1, hue='Fireblight')\n",
    "    plt.legend(loc = 1, bbox_to_anchor = (0,0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27d0782",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sample_UMAP(tmm, samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00ab8d8",
   "metadata": {},
   "source": [
    "## 생각해보기 \n",
    "UMAP은 Clustering을 하기전에 사용하는 차원 축소방법으로 널리 사용되고 있습니다. 그에 비해 현재 PCA는 다른 분석의 전처리 과정으로서 사용되어지는 데 한계가 있는데요. 왜 그럴지 아래 셀에 작성해서 저에게 보여주세요 ^^"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fcd492",
   "metadata": {},
   "source": [
    "# KNN 구연하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1deafb24",
   "metadata": {},
   "source": [
    "![img](https://miro.medium.com/v2/resize:fit:640/format:webp/1*X1KBJctko0RH6BWBsu-XjA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a73d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import neighbors, datasets    # KNN운 neighbors에, 실습할 데이터 iris는 datasets에\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap # KNN의 분류 영역 표시를 위한 컬러맵\n",
    "import mglearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c18c208",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trnx, tstx, trny, tsty = train_test_split(tmm.T, samples[\"Sample\"], test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b004fb7",
   "metadata": {},
   "source": [
    "## 일부데이터를 UMAP을 fitting 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c8658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()\n",
    "\n",
    "# Fit the UMAP object to the data and transform the data to 2D\n",
    "embedding = reducer.fit_transform(trnx)\n",
    "umap_df = pd.DataFrame(embedding)\n",
    "umap_df['Fireblight'] = trny\n",
    "umap_df.head()\n",
    "\n",
    "# Visualize the results using matplotlib\n",
    "sns.scatterplot(data=umap_df, x=0, y=1, hue='Fireblight')\n",
    "plt.legend(loc = 1, bbox_to_anchor = (0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a188ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "tstx_UMAP = reducer.transform(tstx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83fd845",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c5a80e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(10, 3))\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 10]\n",
    "plt.rcParams[\"figure.dpi\"] = 200\n",
    "\n",
    "for n_neighbors, ax in zip([1, 3, 9], axes):\n",
    "    # fit 메서드는 self 객체를 반환합니다.\n",
    "    # 그래서 객체 생성과 fit 메서드를 한 줄에 쓸 수 있습니다.\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors).fit(embedding, trny)\n",
    "    mglearn.plots.plot_2d_separator(clf, embedding, fill=True, eps=0.5, \n",
    "                                    ax=ax, alpha=.4)\n",
    "    mglearn.discrete_scatter(embedding[:, 0], embedding[:, 1], trny, ax=ax)\n",
    "    ax.set_title(\"{} NN\".format(n_neighbors))\n",
    "    ax.set_xlabel(\"trait 0\")\n",
    "    ax.set_ylabel(\"trait 1\")\n",
    "axes[0].legend(loc=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d05ef3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "neighbors_settings = range(1, 11)\n",
    "\n",
    "for n_neighbors in neighbors_settings:\n",
    "    # 모델 생성\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    clf.fit(embedding, trny)\n",
    "    # 훈련 세트 정확도 저장\n",
    "    training_accuracy.append(clf.score(embedding, trny))\n",
    "    # 일반화 정확도 저장\n",
    "    test_accuracy.append(clf.score(tstx_UMAP, tsty))\n",
    "\n",
    "plt.plot(neighbors_settings, training_accuracy, label=\"Train ACC\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label=\"Test ACC\")\n",
    "plt.ylabel(\"ACC\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21243ad5",
   "metadata": {},
   "source": [
    "위 그림에서 성능이 가장 좋은 3을 선택합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4753ad43",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = neighbors.KNeighborsClassifier(n_neighbors=3).fit(embedding, trny)\n",
    "clf.fit(embedding,trny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914db971",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf.score(tstx_UMAP,tsty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de79452d",
   "metadata": {},
   "source": [
    "## 만약 UMAP을 사용하지 않는다면??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd70c87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# UMAP 대신 데이터 전처리를 StandardScaler이용해서 합니다.\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(trnx)\n",
    "trnx_scaled = scaler.transform(trnx)\n",
    "tstx_scaled = scaler.transform(tstx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa88774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf = neighbors.KNeighborsClassifier(n_neighbors=3).fit(trnx, trny)\n",
    "#clf.fit(trnx,trny)\n",
    "#clf.score(tstx_scaled,tsty)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e05e13a",
   "metadata": {},
   "source": [
    "연산시간도 많이 늘어나고<br>\n",
    "(모든 점간 거리 계산을 진행하기 때문에 KNN은 데이터의 수와 차원의 개수의 따라 연산시간이 많이 차이가 난다)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1eb73f",
   "metadata": {},
   "source": [
    "#  Support Vector Machine(SVM)\n",
    "\n",
    "![img](https://velog.velcdn.com/images/shlee0125/post/0a39784c-0859-48f7-8da0-d0a44533e73f/image.png)\n",
    "https://velog.io/@shlee0125/%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D-%EC%A0%95%EB%A6%AC-Support-Vector-Machine-05.-Why-does-SVM-maximize-margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d170a0f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets, svm\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 10]\n",
    "plt.rcParams[\"figure.dpi\"] = 200\n",
    "\n",
    "# we create an instance of SVM and fit out data. We do not scale our\n",
    "# data since we want to plot the support vectors\n",
    "C = 1.0  # SVM regularization parameter\n",
    "models = (\n",
    "    svm.SVC(kernel=\"linear\", C=C),\n",
    "    svm.LinearSVC(C=C, max_iter=10000, dual=\"auto\"),\n",
    "    svm.SVC(kernel=\"rbf\", gamma=0.7, C=C),\n",
    "    svm.SVC(kernel=\"poly\", degree=3, gamma=\"auto\", C=C),\n",
    ")\n",
    "models = (clf.fit(embedding, trny) for clf in models)\n",
    "\n",
    "# title for the plots\n",
    "titles = (\n",
    "    \"SVC with linear kernel\",\n",
    "    \"LinearSVC (linear kernel)\",\n",
    "    \"SVC with RBF kernel\",\n",
    "    \"SVC with polynomial (degree 3) kernel\",\n",
    ")\n",
    "\n",
    "# Set-up 2x2 grid for plotting.\n",
    "fig, sub = plt.subplots(2, 2)\n",
    "plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "X0, X1 = embedding[:, 0], embedding[:, 1]\n",
    "\n",
    "for clf, title, ax in zip(models, titles, sub.flatten()):\n",
    "    disp = DecisionBoundaryDisplay.from_estimator(\n",
    "        clf,\n",
    "        embedding,\n",
    "        response_method=\"predict\",\n",
    "        cmap=plt.cm.coolwarm,\n",
    "        alpha=0.8,\n",
    "        ax=ax,\n",
    "        xlabel= \"Trait 1\",\n",
    "        ylabel= \"Trait 2\",\n",
    "    )\n",
    "    ax.scatter(X0, X1, c=trny, cmap=plt.cm.coolwarm, s=20, edgecolors=\"k\")\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_title(title)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62ce4d3",
   "metadata": {},
   "source": [
    "SVM의 경우에는 너무 차원이 낮아서 오히려 성능이 저하되는 결과를 볼 수 있습니다. \n",
    "\n",
    "다시 차원을 올려서 확인을 해볼까요??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78b8bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "estimator = SVC(kernel=\"linear\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885cf1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = estimator.fit(trnx_scaled, trny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d30c68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.score(tstx_scaled,tsty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e51ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a21ed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = RFECV(estimator, step=1, cv=StratifiedKFold(5), n_jobs=-1,scoring=\"accuracy\")\n",
    "selector = selector.fit(trnx_scaled, trny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5d7abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns 스타일\n",
    "sns.set_style('white')\n",
    "\n",
    "# plot 사이즈\n",
    "plt.rcParams[\"figure.figsize\"] = [10, 4]\n",
    "plt.rcParams[\"figure.dpi\"] = 200\n",
    "\n",
    "n_scores = len(selector.cv_results_[\"mean_test_score\"])\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Mean test accuracy\")\n",
    "plt.errorbar(\n",
    "    range(0, n_scores),\n",
    "    selector.cv_results_[\"mean_test_score\"],\n",
    "    #yerr=selector.cv_results_[\"std_test_score\"],\n",
    ")\n",
    "plt.title(\"Recursive Feature Elimination \\nwith correlated features\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf10e5ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
